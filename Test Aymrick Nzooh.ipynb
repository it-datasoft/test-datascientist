{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvCRy-cITOov"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "! apt install tesseract-ocr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWxKEoi8Zxyw",
        "outputId": "d84ed4a8-e933-4245-e0ac-abbbb78289e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (5,093 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123620 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install Pillow\n",
        "! pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tytYJB7eZ_pD",
        "outputId": "be2fed57-0180-45e3-e692-805f4dba625f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (10.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import ImageEnhance, ImageFilter, Image\n",
        "import spacy\n",
        "from pytesseract import image_to_string\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#import tesseract"
      ],
      "metadata": {
        "id": "Uoilo9oWaMi_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fonction pour convertir l'image en text\n",
        "def convert_image_to_text(img):\n",
        "    print(\"Conversion de l'image en texte...\")\n",
        "    text = image_to_string(img)\n",
        "     # Supprimer les espaces multiples et les sauts de ligne\n",
        "    clean_text_1 = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Supprimer les caractères spéciaux indésirables\n",
        "    clean_text = re.sub(r'[^\\w\\s\\.,:\\-\\+\\(\\)\\[\\]\\{\\}\\?\\!\\;\\\"]', '', clean_text_1)\n",
        "    return clean_text.strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "hYX-8SBuXVrM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_text_to_json(img):\n",
        "    extracted_text = convert_image_to_text(img)\n",
        "    filename = os.path.splitext(img)[0] + \".json\"\n",
        "    json_data = {\n",
        "        \"filename\": img,\n",
        "        \"text\": extracted_text\n",
        "    }\n",
        "    output_json_path = os.path.join(filename)\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
        "        json.dump(json_data, json_file, ensure_ascii=False)\n",
        "    print(f\"Le texte extrait de {img} a été sauvegardé dans {output_json_path}\")"
      ],
      "metadata": {
        "id": "ivqqaHBIXapB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_text_to_json('/content/Inputs/mariage1.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbt2t0hF69vR",
        "outputId": "7eb86710-2ee5-4be3-b06f-3592e066354a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion de l'image en texte...\n",
            "Le texte extrait de /content/Inputs/mariage1.jpg a été sauvegardé dans /content/Inputs/mariage1.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convert_image_to_text('/content/Inputs/passeport3.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "qWwpkC0JXt4C",
        "outputId": "64bab110-a1d3-4110-be08-6194e79e2435"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion de l'image en texte...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ideonité. sagnature et cachet de Fautorite Passeport Type () Code pays (2) WT Pasieport (3) Pp coG GA0240649 Nom (4) MPINI Présoms (5) ADIREL GARLEY EDNICK Date de nalssance (6) Leu de naissarce (77 13. SUILJUL.97 POINTE-NOIR  Natonate 87 Seve (9) f: CONGOLAISE M Protession (10) ETUDIANT Dote détablissement (22) Leu Sémission (13) 4 30 NOVNOV 16 BRAZZAVILLE. Date Sexpiration (12) 29 NOVNOV 21 COGMPINIADIRELGARLEYEDNICK 10 2406497C0G9707139M211129004'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "from spacy"
      ],
      "metadata": {
        "id": "looB1cPbb9Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python -m spacy download fr_core_news_md"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "zHt4Jasae6Nk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NER with Spacy\n",
        "\n",
        "def extract_entities(brute_file):\n",
        "    text = convert_image_to_text(brute_file)\n",
        "    nlp = spacy.load(\"fr_core_news_md\")\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities"
      ],
      "metadata": {
        "id": "musuoI2TdJdQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_entities('/content/Inputs/mariage1.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2FRjr1tdnFO",
        "outputId": "c0ebd49f-fd15-43c5-8c4e-f2cae29d5ebf",
        "collapsed": true
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion de l'image en texte...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('CONGO PROVINCE DU', 'MISC'),\n",
              " ('ACTE DE MARIAGE', 'MISC'),\n",
              " ('CINQUIEME', 'MISC'),\n",
              " ('NOVEMBRE', 'ORG'),\n",
              " ('FRANK', 'ORG'),\n",
              " ('KAFYOTO', 'ORG'),\n",
              " ('Officier', 'ORG'),\n",
              " ('Bourgmestre de la Commune de Manika', 'MISC'),\n",
              " ('Kolwezi', 'LOC'),\n",
              " ('Province duu Lualaba', 'LOC'),\n",
              " ('REPUBLIQUE DEMOCRATIQUE DU CONGO', 'MISC'),\n",
              " ('FARAI CHIRODZERO', 'LOC'),\n",
              " ('ZIMBABWE', 'ORG'),\n",
              " ('DIX-HUITIEME', 'MISC'),\n",
              " ('MARS', 'PER'),\n",
              " ('Ian MIL', 'PER'),\n",
              " ('QUATRE-VINGT ET UN', 'MISC'),\n",
              " ('Monsieur PARADZAI T.CHIRODZERO', 'PER'),\n",
              " ('Madame ENIA', 'PER'),\n",
              " ('Profession', 'LOC'),\n",
              " ('REPUBLIQUE DEMOCRATIQUE DU CONGO', 'MISC'),\n",
              " ('DEUX CENT QUATRE-VINGT-DIX-SEPT', 'MISC'),\n",
              " ('Vavenue UNGU-NGANDU', 'PER'),\n",
              " ('INDUSTRIEL', 'MISC'),\n",
              " ('MANIKA', 'MISC'),\n",
              " ('KOLWEZI', 'MISC'),\n",
              " ('Mademoiselle KAMUZE', 'MISC'),\n",
              " ('KIBAWA', 'ORG'),\n",
              " ('PATRICIA', 'ORG'),\n",
              " ('KOLWEZI', 'MISC'),\n",
              " ('ONZIEME', 'MISC'),\n",
              " ('SEPTEMBRE', 'ORG'),\n",
              " ('Ian MIL', 'PER'),\n",
              " ('CENT QUATRE-VINGT-DEUX', 'MISC'),\n",
              " ('Monsieur', 'PER'),\n",
              " ('MPANGA KAMUZE', 'PER'),\n",
              " ('Madame', 'MISC'),\n",
              " ('KIBAWA', 'ORG'),\n",
              " ('FELIE', 'MISC'),\n",
              " ('CELIBATAIRE', 'MISC'),\n",
              " ('Profession AGENT GENESIS', 'MISC'),\n",
              " ('Nationalité', 'LOC'),\n",
              " ('CONGOLAISE', 'PER'),\n",
              " ('REPUBLIQUE DEMOCRATIQUE', 'LOC'),\n",
              " ('KIPUKA', 'LOC'),\n",
              " ('Quartier', 'LOC'),\n",
              " ('INDUSTRIEL', 'MISC'),\n",
              " ('KOLWEZI', 'MISC'),\n",
              " ('ls', 'MISC'),\n",
              " ('Kolwezi', 'MISC'),\n",
              " ('POfficier', 'MISC'),\n",
              " ('IEtat-Civil', 'MISC'),\n",
              " ('Bourgmestre de la Commune de Manika', 'MISC'),\n",
              " ('Iégalement', 'PER'),\n",
              " ('SOUS LE', 'PER'),\n",
              " ('MATRIMONIAL : COMMUNAUTE UNIVERSELLE DES BIENS', 'MISC'),\n",
              " ('Monsieur', 'PER'),\n",
              " ('NGOIE', 'ORG'),\n",
              " ('QUARANTE-CINQ ans', 'MISC'),\n",
              " ('OPERATEUR ECONOMIQUE', 'MISC'),\n",
              " ('I Avenue JOSEPH KATSHUNG', 'LOC'),\n",
              " ('Quartier JOLI SITE', 'MISC'),\n",
              " ('MUTSHATSHA', 'MISC'),\n",
              " ('KOLWEZI', 'MISC'),\n",
              " ('Madame KASHALE SANDRA', 'PER'),\n",
              " ('Agée de TRENTE-SIX ans', 'PER'),\n",
              " ('Profession: AGENT SPECTRIM', 'MISC'),\n",
              " ('Lo PEtat', 'PER'),\n",
              " ('Lie 2  K FARAI', 'MISC'),\n",
              " ('Frank MAULAKAPYOT', 'PER'),\n",
              " ('Ge MANIKA', 'PER'),\n",
              " ('KIBAWA', 'ORG'),\n",
              " ('PATRICL', 'MISC'),\n",
              " ('Ss eNGorE', 'MISC'),\n",
              " ('L WB', 'ORG')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# Charger le modèle et le tokenizer LayoutLMv3\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
        "\n",
        "# Fonction pour préparer l'entrée\n",
        "def prepare_input(img):\n",
        "    inputs = tokenizer(image_to_string(img), return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    return inputs[\"input_ids\"], inputs[\"attention_mask\"]\n",
        "\n",
        "# Fonction pour extraire les informations\n",
        "def extract_marriage_certificate_info(text):\n",
        "    input_ids, attention_mask = prepare_input(text)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    predictions = outputs.logits.argmax(-1)[0]\n",
        "\n",
        "    # Interprétation des résultats (à compléter selon vos besoins spécifiques)\n",
        "    interpretation = interpret_predictions(predictions)\n",
        "\n",
        "    return interpretation\n",
        "\n",
        "# Fonction d'interprétation des prédictions (à adapter selon vos besoins)\n",
        "def interpret_predictions(predictions):\n",
        "    # Implémentez ici la logique d'interprétation des prédictions\n",
        "    # Par exemple, vous pourriez créer un dictionnaire de correspondance entre les prédictions et les informations extraites\n",
        "    interpretation = {}\n",
        "\n",
        "    # Exemple simplifié :\n",
        "    interpretation[\"informationsEpoux\"] = {\"nom\": \"\", \"prenom\": \"\"}\n",
        "    interpretation[\"informationsEpouse\"] = {\"nom\": \"\", \"prenom\": \"\"}\n",
        "\n",
        "    # Ajoutez plus d'informations selon votre besoin\n",
        "\n",
        "    return interpretation\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sgm_ESu1VDb4",
        "outputId": "ece5d9c8-f796-4962-a07d-a58ad2d5fa5d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_marriage_certificate_info('/content/Inputs/mariage1.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "5j_EnnjiVDRY",
        "outputId": "e364eea5-796e-4e4a-8033-0dbe83c26849"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Words must be of type `List[str]` (single pretokenized example), or `List[List[str]]` (batch of pretokenized examples).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-f3d493c64096>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_marriage_certificate_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Inputs/mariage1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-3aa58f41dfb0>\u001b[0m in \u001b[0;36mextract_marriage_certificate_info\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Fonction pour extraire les informations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_marriage_certificate_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-3aa58f41dfb0>\u001b[0m in \u001b[0;36mprepare_input\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Fonction pour préparer l'entrée\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, boxes, word_labels, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;31m# in case only text is provided => must be words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    282\u001b[0m                     \u001b[0;34m\"Words must be of type `List[str]` (single pretokenized example), \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Words must be of type `List[str]` (single pretokenized example), or `List[List[str]]` (batch of pretokenized examples)."
          ]
        }
      ]
    }
  ]
}